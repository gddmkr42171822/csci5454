\documentclass[12pt]{article}
\setlength{\oddsidemargin}{0in}
\setlength{\evensidemargin}{0in}
\setlength{\textwidth}{6.5in}
\setlength{\parindent}{0in}
\setlength{\parskip}{\baselineskip}

\usepackage{amsmath,amsfonts,amssymb}

\begin{document}

CSCI 5454 \hfill Problem Set 2\\
Robert Werthman

\hrulefill

\begin{enumerate}

	\item \textit{Probability boot camp}
	
	\begin{enumerate}
	
		\item \textit{Prove Markov's inequality, $Pr[X \ge c] \le E[X]/c$, with $c>0$}\\
		\\
		The formula for the probability of a continuous random variable $X$ with probability density function $f(x)$ is
			$$
			Pr[x_1 \le X \le x_2] = \int_{x_1}^{x_2} f(x)dx
			$$	
		And the formula for the expected value of a continuous random variable $X$ with probability density function $f(x)$ is
			$$
			E[x_1 \le X \le x_2] = \int_{x_1}^{x_2} xf(x)
			$$	
		so for $Pr[X \ge c]$ we have
			$$
			Pr[X \ge c] = \int_{c}^{\infty} f(x)dx
			$$
		and since $X$ is a nonnegative random variable we have
			$$
			E[X] = \int_{0}^{\infty} xf(x)dx
			$$
		Notice that $0 < c \le \infty$.  This tells us that the bounds of $E[X]$ are greater than $Pr[X \ge c]$.  We can break up the integral formed by $E[X]$ to create an inequality that 
		will begin to look similar to the integral of $Pr[X \ge c]$.
			\begin{align*}
				E[X] &= \int_{0}^{\infty} xf(x)dx\\
				&= \int_{0}^{c} xf(x)dx + \int_{c}^{\infty} xf(x)dx\\
				&\ge \int_{c}^{\infty} xf(x)dx\\
			\end{align*}
		We can assume that $x \ge c$ because $c$ is one of the bounds of the integral.  This means we can substitute $c$ for $x$.
			\begin{align*}
				 \int_{c}^{\infty} xf(x)dx \ge \int_{c}^{\infty} cf(x)dx \ge c\int_{c}^{\infty} f(x)dx
			\end{align*}
		We now have an equation for $E[X]$ that has $Pr[X \ge c]$.
			$$
			E[X] \ge c\int_{c}^{\infty} f(x)dx = cPr[X \ge c]
			$$
		Dividing both sides by $c$ gives us
			$$
			E[X]/c \ge Pr[X \ge c]
			$$
		which is Markov's inequality.  We have just shown that $Pr[X \ge c] \le E[X]/c$, with $c>0$ is true based on the probability and expected value of the continuous random variable $X$.
		
		\item \textit{Prove Chebyshev's inequality $Pr[|X-\mu| \ge c \cdot \sigma] \le 1/c^2$}\\
		\\
		One of the properties of $|a|$ is that it can also be represented as $\sqrt{a^2}$.\\
		We can then change $|X-\mu|$ to $\sqrt{(X-\mu)^2}$.\\
		If we take the square root of both sides of $\sqrt{(X-\mu)^2} \ge c \cdot \sigma$ we get
		$$
		(X-\mu)^2 \ge (c \cdot \sigma)^2
		$$
		The variance $\sigma^2$ of a continuous random variable $X$ with mean $\mu$ is 
		$$
		\sigma^2 = E[(X-\mu)^2]
		$$
		
		
		\item \textit{Show that for any discrete random variables $X,X',E[X] = E[E[X|X']]$.}
		
		\item \textit{Prove by induction that $E[X_t] = 0$ for a martingale.}
	
	\end{enumerate}


\end{enumerate}

\end{document}