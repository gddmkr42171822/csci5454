'''
Robert Werthman
CSCI 5454
PS4 Questions 1 Part b

Sources
---------
https://stackoverflow.com/questions/3679694/a-weighted-version-of-random-choice
  - Showed me how to create and choose an element with a probability
https://web.eecs.umich.edu/~jabernet/eecs598course/fall2013/web/notes/lec4_091613.pdf
  - Describes how to implement hedge
https://stackoverflow.com/questions/10271484/python-element-wise-multiplication-of-two-lists
  - Show me how to do the dot product of two lists
'''
#from numpy.random import choice
from random import random
import math
import matplotlib.pyplot as plt

def UpdateWeights(learning_rate, weights, loss_vector):
  '''
  Update the weights for each action given the loss vector for 
  a particular round.
  '''
  for i in range(len(weights)):
    x = -learning_rate*loss_vector[i]
    weights[i] = weights[i]*math.exp(x)
  return weights

def GetProbilityDistribution(weights):
  '''
  Creates the probability distribution for a list of weights.
  Each weight may have a different probability.
  '''
  # Create probabilities for each weight/column of the matrix
  probability_distribution = [(weight/sum(weights)) for weight in weights]  
  return probability_distribution

def NatureChoosesLossVector(num_actions):
  '''
  Create a vector/list of random losses for each action
  The losses are between 0 and 1
  
  Returns:
    loss vector 
  '''
  loss_vector = []
  for _ in range(num_actions):
    loss_vector.append(random())
  return loss_vector 

def AlgorithmLoss(weights, loss_vector, probability_distribution):
  '''
  Calculates the algorithm loss by doing a dot product of
  the loss vector and the probability distribution
  
  Returns:
    Algorithm loss 
  '''
  #algorithm_loss = 0.0
  #for i in range(len(weights)):
    #algorithm_loss += weights[i]*loss_vector[i]
  #algorithm_loss = algorithm_loss/sum(weights)
  # dot product of the probability distribution and the loss vector
  algorithm_loss = sum([i*j for (i, j) in zip(loss_vector, probability_distribution)])
  return algorithm_loss
    

def Hedge(learning_rate, rounds, num_actions):
  '''
  Implementation of the Hedge/action setting for game playing
  
  Returns:
    regret for the number of rounds hedge was run for
  '''
  # initialize the weights to 1
  weights = [1.0]*num_actions
  # list that keeps track of the losses for each action for all rounds
  loss_per_action = [0.0]*num_actions
  # float that keeps track of the total algorithm loss for all rounds
  algorithm_loss = 0.0
  for _ in range(rounds):
    # Get the probability distribution from the weights for the actions
    probability_distribution = GetProbilityDistribution(weights)
    # Loss vector generated by nature for each action
    loss_vector = NatureChoosesLossVector(num_actions)
    # Sum the losses for each action each round
    for i in range(len(loss_per_action)):
      loss_per_action[i] += loss_vector[i]
    # Calculate the algorithm loss for the round
    algorithm_loss += AlgorithmLoss(weights, loss_vector, probability_distribution)
    # Update the weigths for each action based on the loss vector
    weights = UpdateWeights(learning_rate, weights, loss_vector)
  
  # Calculate the regret for the given number of rounds
  regret = algorithm_loss - min(loss_per_action)
  return regret

def CreateGraph(regrets, T):
  '''
  Create a graph showing the the regret of hedge is 
  theta(sqrt(T)) where T is the number of rounds
  '''
  c1 = .5
  c2 = 0.01
  c1_T = [c1*math.sqrt(x) for x in T]
  c2_T = [c2*math.sqrt(x) for x in T]
  
  plt.figure()
  a = plt.scatter(T,regrets,color='b')
  b = plt.scatter(T,c1_T,color='g')
  c = plt.scatter(T,c2_T,color='r')
  #plt.ylim(0, 150)
  #plt.xlim(0, 70000)
  plt.title("Plot of Regret, bounded by c1*sqrt(T) and c2*sqrt(T)")
  plt.legend((a,b,c),('Regret', 'c1*sqrt(T)', 'c2*sqrt(T)'), loc=2)
  plt.xlabel('Number of Rounds')
  plt.ylabel('Regret')
  plt.savefig('q1b.png')

def main():
  regrets = []
  T = []
  num_actions = 2
  for i in range(2,300,1):
    rounds = i**2
    T.append(rounds)
    learning_rate = math.sqrt((8*math.log10(num_actions))/rounds)
    regrets.append(Hedge(learning_rate, rounds, num_actions))
 
  CreateGraph(regrets, T)

if __name__ == '__main__':
  main()